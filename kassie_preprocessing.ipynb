{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "kassie_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amelrich/Capstone-Fall-2020/blob/kassie-preprocessing/kassie_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faTOmY4IQ3BO"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas_datareader.data as web\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas_market_calendars as mcal"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwkiiSn4vQ0u",
        "outputId": "592ab2f8-3369-45e5-cd16-5561abe0fd81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "!pip install pandas_market_calendars"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas_market_calendars in /usr/local/lib/python3.6/dist-packages (1.6.0)\n",
            "Requirement already satisfied: trading-calendars in /usr/local/lib/python3.6/dist-packages (from pandas_market_calendars) (1.11.11)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from pandas_market_calendars) (2.8.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from pandas_market_calendars) (2018.9)\n",
            "Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.6/dist-packages (from pandas_market_calendars) (1.1.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.6/dist-packages (from trading-calendars->pandas_market_calendars) (0.11.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from trading-calendars->pandas_market_calendars) (1.18.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil->pandas_market_calendars) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJQjD0txQ3BY"
      },
      "source": [
        "\n",
        "# Start and End date of stock data\n",
        "start_date = pd.to_datetime('1999-11-18')\n",
        "end_date   = pd.to_datetime('2020-09-02')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t7bJ0BASzzJ"
      },
      "source": [
        "# Read names of Stocks we are interested in\n",
        "symbols = pd.read_csv('/sp500.csv',index_col=False)\n",
        "symbols = list(symbols['Symbol'].values)\n",
        "symbols = sorted(symbols)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyIiR8qPthRA"
      },
      "source": [
        "###Set start & end date and find the trading days between them\n",
        "From the `pandas_market_calendars` package, find all the trading dates given a specific range of dates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PxgHLXomkeB"
      },
      "source": [
        "# get trading days calendar\n",
        "def create_market_cal(start, end):\n",
        "    nyse = mcal.get_calendar('NYSE')\n",
        "    schedule = nyse.schedule(start, end)\n",
        "    market_cal = mcal.date_range(schedule, frequency='1D')\n",
        "    market_cal = market_cal.tz_localize(None)\n",
        "    market_cal = [i.replace(hour=0) for i in market_cal]\n",
        "    return market_cal \n",
        "\n",
        "\n",
        "# Start and End date of stock data\n",
        "start_date = pd.to_datetime('1999-11-18')\n",
        "end_date   = pd.to_datetime('2020-09-02')\n",
        "\n",
        "# Create a calendar\n",
        "calendar = create_market_cal(start_date, end_date)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3K1_8nMIOp2"
      },
      "source": [
        "### Split the calendar dates in chunks of length 150\n",
        "We do this because we are interested in data points that capture multiple time scales. We want to capture a stocks behavior over 50 & 100 & 150 days, and have all of this information in one data point that has a fixed length of 50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmqG9fLpILNG",
        "outputId": "5b03b1bf-89a9-43af-c9b7-7e92e177114c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# divide the calendar in 150 day chunks\n",
        "def divide_chunks(l, n): \n",
        "      \n",
        "    # looping till length l \n",
        "    for i in range(0, len(l), n):  \n",
        "        yield l[i:i + n] \n",
        "        \n",
        "# split trading days from start to end date in 50 day chunks\n",
        "n = 150\n",
        "list_of_date_chunk = list(divide_chunks(calendar, n)) \n",
        "print(len(list_of_date_chunk[0]))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVozYUe0JK-Z"
      },
      "source": [
        "### How we achieve multiscale data points\n",
        "\n",
        "If you look at the fuction ```get_multiscale_values``` bellow, we notice that we want to extract infromation from a specific time window. \n",
        "* In order to capture the scale of price of 50 days we can just do `df_start_end[0:50]` and capture the first 50 consecutive days.\n",
        "\n",
        "\n",
        "* In order to capture the timescale of 100 days we `df_start_end[0:100:2]`, thus each time we skip a value in between and are able to capture 100 days prices. We still have a length of 50.\n",
        "\n",
        "Similarly for 150 days.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FjOP1kBRwxw",
        "outputId": "13f14039-4b7b-411c-94d1-776f7d1cf20a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "def get_multiscale_values(df, start, end):\n",
        "  df_start_end = df.loc[start:end]\n",
        "  days_50 = df_start_end[0:50]\n",
        "  days_100 = df_start_end[0:100:2]\n",
        "  days_150 = df_start_end[0:150:3]\n",
        "  return days_50, days_100, days_150\n",
        "\n",
        "def scrape_yahoo(stock_name, start_date, end_date):\n",
        "  # scrape data of each stock from yahoo\n",
        "  try:\n",
        "    df = web.DataReader(stock_name,'yahoo', start_date, end_date) #.rename(columns={'Adj Close': 'Close'})\n",
        "    df = df[['Adj Close','Volume']]\n",
        "    df['Symbol'] =  stock_name\n",
        "    return df\n",
        "  except KeyError:\n",
        "    pass\n",
        "\n",
        "total_prices_list = []\n",
        "total_labels_list = []\n",
        "\n",
        "for stock_name in symbols:\n",
        "  stock_df = scrape_yahoo(stock_name, start_date, end_date)\n",
        "  \n",
        "  tf_prices_list = []\n",
        "  tf_stock_name_list = []\n",
        "  \n",
        "\n",
        "  for item in list_of_date_chunk[:-1]:\n",
        "    start = item[0]\n",
        "    end = item[-1]\n",
        "    days_50, days_100, days_150 = get_multiscale_values(df, start, end)\n",
        "  \n",
        "    dictionary = {'50_days': days_50['Adj Close'].values, '100_days': days_100['Adj Close'].values,\n",
        "        '150_days': days_150['Adj Close'].values}\n",
        "      \n",
        "    datapoint = pd.DataFrame(dictionary)\n",
        "    # create a tensor from those values, both prices and the stock name and add them in a list\n",
        "    price_tensor = tf.convert_to_tensor(datapoint)\n",
        "    stock_name_tensor = tf.convert_to_tensor(stock_name)\n",
        "    tf_prices_list.append(price_tensor)\n",
        "    tf_stock_name_list.append(stock_name_tensor)\n",
        "  \n",
        "  total_prices_list.append(tf_prices_list)\n",
        "  total_labels_list.append(tf_stock_name_list)\n",
        "  print('Stock {} is done'.format(stock_name))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5cbe359a8b6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mdays_50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdays_100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdays_150\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_multiscale_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     dictionary = {'50_days': days_50['Adj Close'].values, '100_days': days_100['Adj Close'].values,\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9ZiySh6F8-4"
      },
      "source": [
        "# we flatten the above total lists that contain all prices for all stocks in S&P\n",
        "flattened_list_prices = [y for x in total_prices_list for y in x]\n",
        "flattened_list_stock_names = [y for x in total_labels_list for y in x]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2kw8-jNGQQt"
      },
      "source": [
        "prices_ds =tf.data.Dataset.from_tensor_slices(tf.stack(flattened_list_prices))\n",
        "names_ds =tf.data.Dataset.from_tensor_slices(tf.stack(flattened_list_stock_names))\n",
        "# we create a data set with the labels and the prices\n",
        "prices_names_ds = tf.data.Dataset.zip((prices_ds, names_ds))\n",
        "print(prices_names_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqjM-EFbHNgd"
      },
      "source": [
        "for price, label in prices_names_ds.take(2):\n",
        "  print(price.shape, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCVvT_LEzNNd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(); datapoint.plot(); plt.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}