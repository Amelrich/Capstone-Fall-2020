{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "kassie_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amelrich/Capstone-Fall-2020/blob/master/padded%26skipped-dct-pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faTOmY4IQ3BO"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas_datareader.data as web\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing  import MinMaxScaler\n",
        "from TS_utils import DCT_lowpass_filter\n",
        "import seaborn as sns\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYwtt89LVKzN",
        "outputId": "7db7d86f-fe13-4baa-e626-79dbd1b66089",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tslearn"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tslearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/67/aa3149fdfef2582d881ce4a5117c9e6a465d5082dd57866904ca508a157c/tslearn-0.4.1-cp36-cp36m-manylinux2010_x86_64.whl (770kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from tslearn) (0.29.21)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from tslearn) (0.48.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from tslearn) (0.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tslearn) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from tslearn) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from tslearn) (0.22.2.post1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->tslearn) (50.3.2)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->tslearn) (0.31.0)\n",
            "Installing collected packages: tslearn\n",
            "Successfully installed tslearn-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_awDS7yOWo0L",
        "outputId": "f6b90d08-2394-486e-a50c-38d174659c27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tslearn.clustering import TimeSeriesKMeans"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jspyxLEVFL7j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a78bc7b9-ba74-443d-9908-1abf9c61102f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk5X3J35Yavt"
      },
      "source": [
        "## Important Note\n",
        "\n",
        "Make sure you have Maxime's TS_utils.py in in this directory so you can import DCT smoothing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwNl5Dy-FGBu"
      },
      "source": [
        "X = None # YOUR TIMESERIES GO HERE\n",
        "#X = np.load(\"/content/drive/My Drive/capstone/timeseries.npy\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDnqk-4VTVwE"
      },
      "source": [
        "################# Helping functions ################# \n",
        "\n",
        "def get_multiscale_skipped_values(df_start_end):\n",
        "  days_60 = df_start_end[-60:]\n",
        "  days_40 = [0 if i % 2 else x for i, x in enumerate(days_60)]\n",
        "  days_20 = [0 if i % 3 else x for i, x in enumerate(days_60)]\n",
        "  dictionary = {'60_days': np.array(days_60), '40_days': np.array(days_40), \n",
        "                '20_days': np.array(days_20)}\n",
        "  return dictionary\n",
        "\n",
        "def get_multiscale_consecutive_values(df_start_end):\n",
        "  days_20 = df_start_end[-20:]\n",
        "  days_40 = df_start_end[-40:]\n",
        "  days_60 = df_start_end[-60:]\n",
        "  \n",
        "  days_20_all = np.append(np.zeros((40)), days_20 ,0)\n",
        "  days_40_all = np.append(np.zeros((20)), days_40,0)\n",
        "  \n",
        "  dictionary = {'20_days': np.array(days_20_all), '40_days': np.array(days_40_all),\n",
        "                    '60_days': days_60}\n",
        "  return dictionary\n",
        "\n",
        "#################################################################### \n",
        "\n",
        "def preprocessing(X):\n",
        "  print(\"Preprocessing Start\")\n",
        "  # scale\n",
        "  X_Scaled = []\n",
        "  for df in X:\n",
        "    scaler = MinMaxScaler()\n",
        "    X_Scaled.append(scaler.fit_transform(df[:,0].reshape(-1, 1)).reshape(1,-1)[0])  \n",
        "\n",
        "  # dct smooth\n",
        "  lowpass_filter = DCT_lowpass_filter()\n",
        "  X_dct_reconstructed = lowpass_filter.fit_transform(np.array(X_Scaled))\n",
        "  X_dct = lowpass_filter.X_dct\n",
        "  n_dct = lowpass_filter.nb_coefs\n",
        "\n",
        "  # create the 3d arrrays for both methods\n",
        "  skipped_values = []\n",
        "  consecutive_values = []\n",
        "  n = 0\n",
        "  for df in X_dct_reconstructed:\n",
        "    n = n + 1\n",
        "    if n%1000 == 0:\n",
        "      print(\"{} stocksout of {} completed\".format(n,len(X_dct_reconstructed)))\n",
        "  \n",
        "    dictionary_skipped_values = get_multiscale_skipped_values(df)\n",
        "    dictionary_consecutive_values = get_multiscale_consecutive_values(df)\n",
        " \n",
        "    datapoint_skipped_values = pd.DataFrame(dictionary_skipped_values).to_numpy()\n",
        "    datapoint_consecutive_values = pd.DataFrame(dictionary_consecutive_values).to_numpy()\n",
        "    skipped_values.append(datapoint_skipped_values)\n",
        "    consecutive_values.append(datapoint_consecutive_values)\n",
        "  \n",
        "  print(\"Preprocessing Done\")\n",
        "  return skipped_values, consecutive_values\n",
        "\n",
        "def clustering(x):\n",
        "  num_clus = 6\n",
        "  km_skipped = TimeSeriesKMeans(n_clusters=num_clus, max_iter=5, metric='dtw',random_state=0).fit(x)\n",
        "  return km_skipped.predict(x)\n",
        "\n",
        "def preprocessing_clustering(x):\n",
        "  skipped_values, consecutive_values  = preprocessing(x)\n",
        "  print(\"Starting to cluster both arrays...\")\n",
        "  x_clusters_skipped = clustering(skipped_values)\n",
        "  x_clusters_consecutive = clustering(consecutive_values)\n",
        "  print(\"Finished!\")\n",
        "  return x_clusters_skipped, x_clusters_consecutive"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3RTtoEsWxa7",
        "outputId": "0198cfc1-6351-483f-8e48-f1fb17a8b67c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_clusters_skipped, x_clusters_consecutive = preprocessing_clustering(X)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing Start\n",
            "1000 stocksout of 4000 completed\n",
            "2000 stocksout of 4000 completed\n",
            "3000 stocksout of 4000 completed\n",
            "4000 stocksout of 4000 completed\n",
            "Preprocessing Done\n",
            "Starting to cluster both arrays...\n",
            "Finished!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzcR9sJ7XuxL",
        "outputId": "6488f530-d7b9-43ae-e637-c18540187e91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_clusters_skipped"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 3, 0, ..., 3, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-DarF4ZY4gy"
      },
      "source": [
        "x_clusters_consecutive"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}