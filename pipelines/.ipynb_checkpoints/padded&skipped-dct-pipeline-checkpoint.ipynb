{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Amelrich/Capstone-Fall-2020/blob/master/padded%26skipped-dct-pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Max Tchibozo\\Desktop\\CAPSTONE\\Capstone-Fall-2020\\pipelines\n",
      "C:\\Users\\Max Tchibozo\\Desktop\\CAPSTONE\\Capstone-Fall-2020\\utilities\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current = os.getcwd()\n",
    "print(current)\n",
    "os.chdir('../utilities')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faTOmY4IQ3BO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing  import MinMaxScaler\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../utilities/')\n",
    "from TS_utils import DCT_lowpass_filter\n",
    "\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oYwtt89LVKzN",
    "outputId": "7db7d86f-fe13-4baa-e626-79dbd1b66089"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tslearn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/67/aa3149fdfef2582d881ce4a5117c9e6a465d5082dd57866904ca508a157c/tslearn-0.4.1-cp36-cp36m-manylinux2010_x86_64.whl (770kB)\n",
      "\u001b[K     |████████████████████████████████| 778kB 6.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from tslearn) (0.29.21)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from tslearn) (0.48.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from tslearn) (0.17.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tslearn) (1.18.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from tslearn) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from tslearn) (0.22.2.post1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->tslearn) (50.3.2)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->tslearn) (0.31.0)\n",
      "Installing collected packages: tslearn\n",
      "Successfully installed tslearn-0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tslearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_awDS7yOWo0L",
    "outputId": "f6b90d08-2394-486e-a50c-38d174659c27"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jspyxLEVFL7j",
    "outputId": "a78bc7b9-ba74-443d-9908-1abf9c61102f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wk5X3J35Yavt"
   },
   "source": [
    "## Important Note\n",
    "\n",
    "Make sure you have Maxime's TS_utils.py in in this directory so you can import DCT smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uwNl5Dy-FGBu"
   },
   "outputs": [],
   "source": [
    "X = None # YOUR TIMESERIES GO HERE\n",
    "#X = np.load(\"/content/drive/My Drive/capstone/timeseries.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "pDnqk-4VTVwE"
   },
   "outputs": [],
   "source": [
    "################# Helping functions ################# \n",
    "\n",
    "def get_multiscale_skipped_values(df_start_end):\n",
    "  days_60 = df_start_end[-60:]\n",
    "  days_40 = [0 if i % 2 else x for i, x in enumerate(days_60)]\n",
    "  days_20 = [0 if i % 3 else x for i, x in enumerate(days_60)]\n",
    "  dictionary = {'60_days': np.array(days_60), '40_days': np.array(days_40), \n",
    "                '20_days': np.array(days_20)}\n",
    "  return dictionary\n",
    "\n",
    "def get_multiscale_consecutive_values(df_start_end):\n",
    "  days_20 = df_start_end[-20:]\n",
    "  days_40 = df_start_end[-40:]\n",
    "  days_60 = df_start_end[-60:]\n",
    "  \n",
    "  days_20_all = np.append(np.zeros((40)), days_20 ,0)\n",
    "  days_40_all = np.append(np.zeros((20)), days_40,0)\n",
    "  \n",
    "  dictionary = {'20_days': np.array(days_20_all), '40_days': np.array(days_40_all),\n",
    "                    '60_days': days_60}\n",
    "  return dictionary\n",
    "\n",
    "#################################################################### \n",
    "\n",
    "def preprocessing(X):\n",
    "  print(\"Preprocessing Start\")\n",
    "  # scale\n",
    "  X_Scaled = []\n",
    "  for df in X:\n",
    "    scaler = MinMaxScaler()\n",
    "    X_Scaled.append(scaler.fit_transform(df[:,0].reshape(-1, 1)).reshape(1,-1)[0])  \n",
    "\n",
    "  # dct smooth\n",
    "  lowpass_filter = DCT_lowpass_filter()\n",
    "  X_dct_reconstructed = lowpass_filter.fit_transform(np.array(X_Scaled))\n",
    "  X_dct = lowpass_filter.X_dct\n",
    "  n_dct = lowpass_filter.nb_coefs\n",
    "\n",
    "  # create the 3d arrrays for both methods\n",
    "  skipped_values = []\n",
    "  consecutive_values = []\n",
    "  n = 0\n",
    "  for df in X_dct_reconstructed:\n",
    "    n = n + 1\n",
    "    if n%1000 == 0:\n",
    "      print(\"{} stocksout of {} completed\".format(n,len(X_dct_reconstructed)))\n",
    "  \n",
    "    dictionary_skipped_values = get_multiscale_skipped_values(df)\n",
    "    dictionary_consecutive_values = get_multiscale_consecutive_values(df)\n",
    " \n",
    "    datapoint_skipped_values = pd.DataFrame(dictionary_skipped_values).to_numpy()\n",
    "    datapoint_consecutive_values = pd.DataFrame(dictionary_consecutive_values).to_numpy()\n",
    "    skipped_values.append(datapoint_skipped_values)\n",
    "    consecutive_values.append(datapoint_consecutive_values)\n",
    "  \n",
    "  print(\"Preprocessing Done\")\n",
    "  return skipped_values, consecutive_values\n",
    "\n",
    "def clustering(x):\n",
    "  num_clus = 6\n",
    "  km_skipped = TimeSeriesKMeans(n_clusters=num_clus, max_iter=5, metric='dtw',random_state=0).fit(x)\n",
    "  return km_skipped.predict(x)\n",
    "\n",
    "def preprocessing_clustering(x):\n",
    "  skipped_values, consecutive_values  = preprocessing(x)\n",
    "  print(\"Starting to cluster both arrays...\")\n",
    "  x_clusters_skipped = clustering(skipped_values)\n",
    "  x_clusters_consecutive = clustering(consecutive_values)\n",
    "  print(\"Finished!\")\n",
    "  return x_clusters_skipped, x_clusters_consecutive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U3RTtoEsWxa7",
    "outputId": "0198cfc1-6351-483f-8e48-f1fb17a8b67c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Start\n",
      "1000 stocksout of 4000 completed\n",
      "2000 stocksout of 4000 completed\n",
      "3000 stocksout of 4000 completed\n",
      "4000 stocksout of 4000 completed\n",
      "Preprocessing Done\n",
      "Starting to cluster both arrays...\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "x_clusters_skipped, x_clusters_consecutive = preprocessing_clustering(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nzcR9sJ7XuxL",
    "outputId": "6488f530-d7b9-43ae-e637-c18540187e91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 0, ..., 3, 1, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_clusters_skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r-DarF4ZY4gy"
   },
   "outputs": [],
   "source": [
    "x_clusters_consecutive"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "kassie_preprocessing.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
